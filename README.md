library to communicate directly with local llama.cpp server.
should probably have named this custom-llama.
probably doesn't work with openai because i think their api parameters are different.
